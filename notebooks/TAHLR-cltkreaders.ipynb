{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this cell to install cltk-readers the first time; you do not need to run\n",
    "## this cell again if the installation in successful.\n",
    "\n",
    "# !pip install -U git+https://github.com/diyclassics/cltk_readers.git#egg=cltk-readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "import random\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the corpus reader\n",
    "\n",
    "CR = LatinTesseraeCorpusReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fileids\n",
    "\n",
    "files = CR.fileids()\n",
    "print(f'There are {len(files)} files in this text collection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset corpus by metadata\n",
    "\n",
    "epic = CR.fileids(genre='epic')\n",
    "pprint(random.sample(epic, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset corpus by filename match\n",
    "\n",
    "eclogues = CR.fileids(match='eclogues')\n",
    "pprint(eclogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = next(CR.texts(eclogues))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = next(CR.spacy_docs(eclogues))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc[:5]:\n",
    "    data.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.ent_type_])\n",
    "\n",
    "print(tabulate(data, headers=['Text', 'Lemma', 'POS', 'Tag', 'Dependency', 'Entity Type']))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sents\n",
    "\n",
    "sents = list(CR.sents(eclogues))\n",
    "for i, sent in enumerate(sents[:5]):\n",
    "    print(f'Sentence {i}: {sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(CR.tokens(eclogues))\n",
    "for i, token in enumerate(tokens[:5]):\n",
    "    print(f'Token {i}: {token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_token = next(CR.tokens(eclogues))\n",
    "print(sample_token._.citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sample_token._.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
